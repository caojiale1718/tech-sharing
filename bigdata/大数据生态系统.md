本文搜集整理与大数据相关的资料，主要包含大数据平台组件的快速使用指南、组件的功能、实现原理、以及相关重要概念。

想要全面了解大数据生态系统的所有组件，可以参考其他人整理的[大数据生态系统表](http://hadoopecosystemtable.github.io)。本文只关注我们会使用的部分组件。

## Hadoop系列
#### 快速使用指南
- [单机/伪分布式配置教程](http://www.powerxing.com/install-hadoop/)，基本上是对官网的翻译，通过里面的例子对Hadoop上的MapReduce会有一个更直观的感受
- 在上文的基础上，[Hadoop集群配置教程](http://www.powerxing.com/install-hadoop-cluster/)详细描述了Ubuntu/CentOS上集群的安装与注意事项

#### 组件功能、原理与概念
- [Hadoop面试，有它就够了](http://www.jianshu.com/p/c97ff0ab5f49)，通过图文的方式详细说明MapReduce架构以及演进。包括以下几个方面：
    - Hadoop 1.0中JobTracker和TaskTracker的工作方式
    - shuffle：集群中各个节点上的数据迁移
    - Hadoop 2.0的MapReduce框架YARN与1.0版本的对比，详细内容参考[YARN与MRv1的对比](http://www.cnblogs.com/BYRans/p/5509403.html)
    - YARN管理资源调度的几个重要组件是ResourceManager、NodeManager、ApplicationMaster、Containers，Client，详细内容参考[YARN基本框架介绍](http://www.cnblogs.com/BYRans/p/5513991.html)
- [专门为面试而学的大数据](http://www.jianshu.com/p/9b1304a1db4d)，也从几个方面讲述Hadoop中的重要组件：
    - HDFS中的模块：管理模块NameNode、数据存储DataNode，备份模块Secondary NameNode、**安全模式**
    - MapReduce工作原理，详见上文
    - 分布式组件管理者ZooKeeper的角色概念，以及自身的备份恢复。ZooKeeper一般用来管理像Kafka这类自身不具备备份容灾机制的大数据组件
    - 构建在HDFS上的分布式列式存储系统HBase，与HDFS的区别是，HBase主要用于存储结构化数据，HDFS可以存储任意形式的数据
    - **HBase的存储结构图**
- [Hadoop HDFS详解](http://zheming.wang/blog/2015/07/24/17505A21-0204-48AB-8EBE-EAC911B22821/)，详细讲解HDFS架构、模块、重要特性
- [Hadoop Map/Reduce执行流程详解](http://zheming.wang/blog/2015/05/19/3AFF5BE8-593C-4F76-A72A-6A40FB140D4D/)，深入阐述作业的提交与执行过程
- [Kafka系列文章](http://blog.csdn.net/suifeng3051/article/category/2386223)，其中最基本的概念：topic是producer/consumer生产与消费的消息存放的目录
    - [Kafka设计与原理详解](http://blog.csdn.net/suifeng3051/article/details/48053965)是对这一系列文章的总结
- 为分布式系统提供一致性协调服务的[ZooKeeper原理与实现](http://www.wuzesheng.com/?p=2609) 

#### 实践与调优
- [Hadoop常见问题解决方案总结](http://zheming.wang/blog/2015/05/09/6C1B32E8-BC5F-4D31-AF20-B5DB048B46C3/)，从执行性能、作业故障、常用技巧、易错点四个方面分类阐述
- [HBase复制详解](http://weizijun.cn/2016/05/27/HBase复制详解/)，记录工程实践中用到的HBase复制技术

## Spark系列
#### 快速使用指南
- [Spark快速入门-1.6.0](http://www.cnblogs.com/BYRans/p/5199824.html)，[Spark编程指南-1.6.0](http://www.cnblogs.com/BYRans/p/5292763.html)
- 官方最新Spark 2.0.0指南[Quick Start](http://spark.apache.org/docs/latest/quick-start.html)，[Spark Programming Guide](http://spark.apache.org/docs/latest/programming-guide.html)
- Spark 2.0.0的[新特性介绍](http://litaotao.github.io/spark-2.0-faster-easier-smarter)，重点关注**统一DataFrames and Datasets API**与**SparkSession**

#### 组件功能、原理与概念
- RDD本质上是满足[五个主要属性](http://litaotao.github.io/spark-what-is-rdd)的数据结构
- [Spark基本概念解析](http://litaotao.github.io/spark-questions-concepts)
- [深入研究Spark运行原理之job,stage,task](http://litaotao.github.io/deep-into-spark-exection-model)，通过例子讲解如何把用户程序转换为可执行的任务
- 内存分布式文件系统[Alluxio中文文档](http://www.alluxio.org/docs/1.2/cn/index.html)

#### 实践与调优
- 美团Spark性能调优[基础篇](http://tech.meituan.com/spark-tuning-basic.html)、[高级篇](http://tech.meituan.com/spark-tuning-pro.html)

## 问题与总结
#### 配置问题
- YARN资源管理页(http://master:8088/cluster)，关注资源状态。由于配置文件的参数原因，有可能系统启动了，但是资源并没有加到集群
- Hadoop信息页(http://master:50070)，关注集群的整体情况与文件系统
- 初次配置时不要放过Hadoop/Spark日志目录下的任何警告与错误`grep -re "\(WARN\|ERROR\)" logs/*`，同时也要关注启动时的INFO类别日志
- Ubuntu系统要注释掉`/etc/hosts`文件中包含`127.0.1.1`那行，**如果你知道原因请告诉我**
- CentOS系统确认iptables处于关闭状态，我猜测不需要完全关闭iptables，只要允许集群使用的IP或端口应该也是可行的

#### 应用程序
- **TODO**
